"""
Full Pipeline Worker ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –≤—Å–µ–≥–æ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –ø–æ–¥ –∫–ª—é—á
WS ‚Üí Direct ‚Üí Clustering ‚Üí Minus ‚Üí Export, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–¥–∞—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å—Ü–µ–Ω
"""
from __future__ import annotations

import asyncio
import json
import os
import sys
import time
import traceback
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple

from PySide6.QtCore import QThread, Signal

# –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å–µ—Ä–≤–∏—Å—ã
# –°–µ—Ä–≤–∏—Å—ã –≤—ã–∑—ã–≤–∞—é—Ç—Å—è –∫–∞–∫ –æ–±—ã—á–Ω—ã–µ python-—Ñ—É–Ω–∫—Ü–∏–∏/–∫–æ—Ä—É—Ç–∏–Ω—ã, –æ–∂–∏–¥–∞–µ–º—ã–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞:
# - frequency.run_frequency_batch(queries: List[str], region: int, out_dir: Path) -> Path
# - direct_batch.run_direct_batch(input_path: Path, out_dir: Path) -> Path
# - clustering.run_clustering(input_path: Path, out_dir: Path) -> Path
# - minus_words.run_minus_words(input_path: Path, out_dir: Path) -> Path
# - export.run_export(input_path: Path, out_dir: Path) -> Path
# –ï—Å–ª–∏ —É –º–æ–¥—É–ª—è –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è –∏–º–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–π ‚Äî –∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –≤ ServiceAdapter –Ω–∏–∂–µ.

try:
    from services import frequency as frequency_service
except Exception:  # –ª–æ–≥–∏—Ä—É–µ–º, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ CLI-–æ–±–µ—Ä—Ç–∫–∏
    frequency_service = None

try:
    from services import direct_batch as direct_service
except Exception:
    direct_service = None

# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –º–æ–∂–µ—Ç –ª–µ–∂–∞—Ç—å –≤ core/services/utils ‚Äî –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–º–ø–æ—Ä—Ç–æ–≤
clustering_service = None
for mod_path in (
    "services.clustering",
    "core.clustering",
    "utils.clustering",
    "services.cluster",
    "core.cluster",
):
    if clustering_service is None:
        try:
            clustering_service = __import__(mod_path, fromlist=["*"])
        except Exception:
            pass

try:
    from services import minus_words as minus_service
except Exception:
    minus_service = None

# –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
export_service = None
for mod_path in (
    "services.export",
    "core.export",
    "utils.export",
    "services.exporter",
):
    if export_service is None:
        try:
            export_service = __import__(mod_path, fromlist=["*"])
        except Exception:
            pass


@dataclass
class StageResult:
    name: str
    input_path: Optional[Path]
    output_path: Optional[Path]
    ok: bool
    meta: Dict[str, Any]


class ServiceAdapter:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –≤—ã–∑–æ–≤–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π —Å–µ—Ä–≤–∏—Å–æ–≤ –µ–¥–∏–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º."""

    @staticmethod
    async def run_frequency(queries: List[str], region: int, out_dir: Path) -> Path:
        # –ü–æ–ø—ã—Ç–∫–∞ 1: –Ω–∞—Ç–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        if frequency_service and hasattr(frequency_service, "run_frequency_batch"):
            return await _maybe_await(
                frequency_service.run_frequency_batch(queries=queries, region=region, out_dir=out_dir)
            )
        # –ü–æ–ø—ã—Ç–∫–∞ 2: –≤–æ–∑–º–æ–∂–Ω–∞—è sync-—Ñ—É–Ω–∫—Ü–∏—è
        if frequency_service and hasattr(frequency_service, "run"):
            return await _maybe_await(
                frequency_service.run(queries=queries, region=region, out_dir=out_dir)
            )
        # –ü–æ–ø—ã—Ç–∫–∞ 3: CLI
        return await _run_cli([
            sys.executable,
            "-m",
            "services.frequency",
            "--region",
            str(region),
            "--out",
            str(out_dir),
            "--queries",
            json.dumps(queries, ensure_ascii=False),
        ])

    @staticmethod
    async def run_direct(input_path: Path, out_dir: Path) -> Path:
        if direct_service and hasattr(direct_service, "run_direct_batch"):
            return await _maybe_await(
                direct_service.run_direct_batch(input_path=input_path, out_dir=out_dir)
            )
        if direct_service and hasattr(direct_service, "run"):
            return await _maybe_await(
                direct_service.run(input_path=input_path, out_dir=out_dir)
            )
        return await _run_cli([
            sys.executable,
            "-m",
            "services.direct_batch",
            "--in",
            str(input_path),
            "--out",
            str(out_dir),
        ])

    @staticmethod
    async def run_clustering(input_path: Path, out_dir: Path) -> Path:
        if clustering_service:
            for fn in ("run_clustering", "run", "cluster_batch"):
                if hasattr(clustering_service, fn):
                    return await _maybe_await(
                        getattr(clustering_service, fn)(input_path=input_path, out_dir=out_dir)
                    )
        return await _run_cli([
            sys.executable,
            "-m",
            "services.clustering",
            "--in",
            str(input_path),
            "--out",
            str(out_dir),
        ])

    @staticmethod
    async def run_minus(input_path: Path, out_dir: Path) -> Path:
        if minus_service and hasattr(minus_service, "run_minus_words"):
            return await _maybe_await(
                minus_service.run_minus_words(input_path=input_path, out_dir=out_dir)
            )
        if minus_service and hasattr(minus_service, "run"):
            return await _maybe_await(
                minus_service.run(input_path=input_path, out_dir=out_dir)
            )
        return await _run_cli([
            sys.executable,
            "-m",
            "services.minus_words",
            "--in",
            str(input_path),
            "--out",
            str(out_dir),
        ])

    @staticmethod
    async def run_export(input_path: Path, out_dir: Path) -> Path:
        if export_service:
            for fn in ("run_export", "run", "export_batch"):
                if hasattr(export_service, fn):
                    return await _maybe_await(
                        getattr(export_service, fn)(input_path=input_path, out_dir=out_dir)
                    )
        # CLI fallback
        return await _run_cli([
            sys.executable,
            "-m",
            "services.export",
            "--in",
            str(input_path),
            "--out",
            str(out_dir),
        ])


async def _maybe_await(result):
    if asyncio.iscoroutine(result):
        return await result
    return result


async def _run_cli(cmd: List[str]) -> Path:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–¥–ø—Ä–æ—Ü–µ—Å—Å, –æ–∂–∏–¥–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤—ã—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å –∏–∑ stdout."""
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        cwd=str(Path.cwd()),
    )
    stdout, stderr = await proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"Command failed: {' '.join(cmd)}\n{stderr.decode(errors='ignore')}")
    # –û–∂–∏–¥–∞–µ–º, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–≤–µ–¥–µ—Ç –ø—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π JSON: {"output": "/path"}
    try:
        data = json.loads(stdout.decode(errors="ignore"))
        out = Path(data.get("output"))
        if not out.exists():
            raise FileNotFoundError(out)
        return out
    except Exception as e:
        raise RuntimeError(f"Invalid CLI output for {' '.join(cmd)}: {e}\nSTDOUT: {stdout[:500].decode(errors='ignore')}")


class FullPipelineWorkerThread(QThread):
    """–ü–æ—Ç–æ–∫ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω–≤–µ–π–µ—Ä–∞: WS ‚Üí Direct ‚Üí Clustering ‚Üí Minus ‚Üí Export."""

    # –≤—Ä–µ–º—è, —Ñ—Ä–∞–∑–∞, —á–∞—Å—Ç–æ—Ç–∞, CPC, –ø–æ–∫–∞–∑—ã, –±—é–¥–∂–µ—Ç, –≥—Ä—É–ø–ø–∞, —Å—Ç–∞—Ç—É—Å
    log_signal = Signal(str, str, str, str, str, str, str, str)
    # –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, —É—Å–ø–µ—à–Ω–æ, –æ—à–∏–±–æ–∫, —Å–∫–æ—Ä–æ—Å—Ç—å, –≤—Ä–µ–º—è
    stats_signal = Signal(int, int, int, float, float)
    # –æ–±—â–∏–π –ª–æ–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
    log_message = Signal(str)
    error_signal = Signal(str)
    # —Ç–µ–∫—É—â–∏–π, –≤—Å–µ–≥–æ, —ç—Ç–∞–ø
    progress_signal = Signal(int, int, str)
    finished_signal = Signal(bool, str)
    # –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤/–æ–±—ä–µ–∫—Ç–æ–≤) –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã/–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    results_ready = Signal(list)

    def __init__(self, queries: Optional[List[str]] = None, region: int = 225,
                 task_file: Optional[str] = None, out_root: Optional[str] = None):
        super().__init__()
        self.queries = queries or []
        self.region = region
        self.task_file = task_file
        self.out_root = Path(out_root) if out_root else Path("runtime/outputs")
        self._cancelled = False
        self.start_time: Optional[float] = None

    # –ü—É–±–ª–∏—á–Ω—ã–µ API
    def cancel(self):
        self._cancelled = True

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
    def run(self):
        self.log_message.emit(f"üöÄ –ó–∞–ø—É—Å–∫ Full Pipeline, –≤—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.start_time = time.time()
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            results = loop.run_until_complete(self._run_pipeline())
            self.results_ready.emit([str(p) for p in results if p])
            self.finished_signal.emit(True, "–ì–æ—Ç–æ–≤–æ")
        except Exception:
            err = traceback.format_exc()
            self.error_signal.emit(err)
            self.finished_signal.emit(False, "–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –¥–µ—Ç–∞–ª–∏ –≤ –ª–æ–≥–µ")
        finally:
            try:
                loop.close()
            except Exception:
                pass

    async def _run_pipeline(self) -> List[Path]:
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–¥–∞—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: multiple scenes
        if self.task_file:
            return await self._run_from_task_file(Path(self.task_file))
        # –ò–Ω–∞—á–µ ‚Äî –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–≥–æ–Ω –ø–æ self.queries
        return await self._run_single_scene(self.queries, scene_name="ad-hoc")

    async def _run_from_task_file(self, path: Path) -> List[Path]:
        if not path.exists():
            raise FileNotFoundError(f"Task file not found: {path}")
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        scenes: List[Dict[str, Any]] = data.get("scenes") or []
        results: List[Path] = []
        self.log_message.emit(f"üîß –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ü–µ–Ω: {len(scenes)} –∏–∑ {path}")
        for idx, scene in enumerate(scenes, start=1):
            if self._cancelled:
                self.log_message.emit("‚õî –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            queries = scene.get("queries") or []
            region = int(scene.get("region") or self.region)
            name = scene.get("name") or f"scene_{idx:02d}"
            self.log_message.emit(f"‚ñ∂Ô∏è –°—Ü–µ–Ω–∞ {idx}/{len(scenes)}: {name}, —Ñ—Ä–∞–∑: {len(queries)}, —Ä–µ–≥–∏–æ–Ω: {region}")
            out_files = await self._run_single_scene(queries, region=region, scene_name=name)
            results.extend(out_files)
        return results

    async def _run_single_scene(self, queries: List[str], region: Optional[int] = None, scene_name: str = "scene") -> List[Path]:
        region = int(region or self.region)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_out = self.out_root / f"{scene_name}_{ts}"
        ws_out = base_out / "ws"
        dr_out = base_out / "direct"
        cl_out = base_out / "cluster"
        mn_out = base_out / "minus"
        ex_out = base_out / "export"
        for d in (ws_out, dr_out, cl_out, mn_out, ex_out):
            d.mkdir(parents=True, exist_ok=True)

        outputs: List[Path] = []

        # 1) Wordstat / Frequency
        self._progress(1, 5, f"Wordstat/Frequency: {len(queries)} —Ñ—Ä–∞–∑, —Ä–µ–≥–∏–æ–Ω {region}")
        ws_path: Path = await ServiceAdapter.run_frequency(queries=queries, region=region, out_dir=ws_out)
        self.log_message.emit(f"‚úÖ Frequency –≥–æ—Ç–æ–≤–æ: {ws_path}")
        outputs.append(ws_path)

        # 2) Direct Batch
        self._progress(2, 5, "Direct Batch: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–º–ø–∞–Ω–∏–π/–≥—Ä—É–ø–ø")
        dr_path: Path = await ServiceAdapter.run_direct(input_path=ws_path, out_dir=dr_out)
        self.log_message.emit(f"‚úÖ Direct –≥–æ—Ç–æ–≤–æ: {dr_path}")
        outputs.append(dr_path)

        # 3) Clustering
        self._progress(3, 5, "Clustering: –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ —Å–µ–º–∞–Ω—Ç–∏–∫–∞")
        cl_path: Path = await ServiceAdapter.run_clustering(input_path=dr_path, out_dir=cl_out)
        self.log_message.emit(f"‚úÖ Clustering –≥–æ—Ç–æ–≤–æ: {cl_path}")
        outputs.append(cl_path)

        # 4) Minus-—Å–ª–æ–≤–∞
        self._progress(4, 5, "–ú–∏–Ω—É—Å–æ–≤–∫–∞: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∏–Ω—É—Å-—Å–ª–æ–≤")
        mn_path: Path = await ServiceAdapter.run_minus(input_path=cl_path, out_dir=mn_out)
        self.log_message.emit(f"‚úÖ –ú–∏–Ω—É—Å–æ–≤–∫–∞ –≥–æ—Ç–æ–≤–æ: {mn_path}")
        outputs.append(mn_path)

        # 5) Export
        self._progress(5, 5, "–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        ex_path: Path = await ServiceAdapter.run_export(input_path=mn_path, out_dir=ex_out)
        self.log_message.emit(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≥–æ—Ç–æ–≤–æ: {ex_path}")
        outputs.append(ex_path)

        return outputs

    def _progress(self, cur: int, total: int, stage: str):
        if self.start_time:
            elapsed = time.time() - self.start_time
            speed = cur / max(elapsed, 1e-6)
            self.stats_signal.emit(cur, cur, 0, speed, elapsed)
        self.progress_signal.emit(cur, total, stage)
        self.log_message.emit(f"‚û°Ô∏è {stage}")


# –£—Ç–∏–ª–∏—Ç–∞ CLI –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —ç—Ç–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞ (–±–µ–∑ GUI)
# –ü—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (tasks.json):
# {
#   "scenes": [
#     {"name": "niche_1", "region": 213, "queries": ["–∫—É–ø–∏—Ç—å –ø—ã–ª–µ—Å–æ—Å", "–ø—ã–ª–µ—Å–æ—Å dyson"]},
#     {"name": "niche_2", "queries": ["—Ä–æ–±–æ—Ç –ø—ã–ª–µ—Å–æ—Å", "wet&dry vacuum"]}
#   ]
# }
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Full pipeline worker runner")
    parser.add_argument("--tasks", dest="tasks", type=str, help="–ü—É—Ç—å –∫ –∑–∞–¥–∞—á–Ω–æ–º—É —Ñ–∞–π–ª—É JSON", default=None)
    parser.add_argument("--queries", dest="queries", type=str, help="JSON-–º–∞—Å—Å–∏–≤ —Ñ—Ä–∞–∑ –¥–ª—è ad-hoc –∑–∞–ø—É—Å–∫–∞", default=None)
    parser.add_argument("--region", dest="region", type=int, default=225)
    parser.add_argument("--out", dest="out", type=str, default="runtime/outputs")

    args = parser.parse_args()

    queries: List[str] = []
    task_file: Optional[str] = args.tasks
    if args.queries:
        try:
            queries = json.loads(args.queries)
        except Exception:
            print("[ERR] --queries –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å JSON-–º–∞—Å—Å–∏–≤–æ–º —Å—Ç—Ä–æ–∫", file=sys.stderr)
            sys.exit(2)

    # –ë–µ–∑ GUI-—Å–∏–≥–Ω–∞–ª–æ–≤: –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏ –Ω–∞–ø–µ—á–∞—Ç–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏
    worker = FullPipelineWorkerThread(
        queries=queries,
        region=args.region,
        task_file=task_file,
        out_root=args.out,
    )

    # –ü—Ä–æ—Å—Ç–µ–π—à–∏–µ
